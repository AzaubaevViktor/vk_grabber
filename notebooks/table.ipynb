{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from lxml import etree\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(\"../data/annot.opcorpora.xml\", \"rt\") as f:\n",
    "    root = etree.fromstring(f.read().encode())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def _parse_text_el(text_el):\n",
    "    for paragraph in text_el.find('paragraphs').getchildren():\n",
    "        for sentence in paragraph.getchildren():\n",
    "            # TODO: Clean\n",
    "            for token in sentence.find('tokens').getchildren():\n",
    "                text = token.get('text')\n",
    "                lemma = token.find(\".//l\").get('t')\n",
    "                yield text, lemma\n",
    "            yield None, None\n",
    "\n",
    "# tuple(_parse_text_el(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "good_chars = \"абвгдежзийклмнопрстуфхцчшщъыьэюя\"\n",
    "good_chars += good_chars.upper()\n",
    "\n",
    "def _cleanup(raw_text):\n",
    "    return \"\".join(ch.lower() if ch in good_chars else ' '\n",
    "                   for ch in raw_text)\n",
    "\n",
    "def _do_filter(_out):\n",
    "    for text, lemma in _out:\n",
    "        if text is None:\n",
    "            yield text, lemma\n",
    "            continue\n",
    "\n",
    "        if text := _cleanup(text).strip():\n",
    "            yield text, _cleanup(lemma).strip()\n",
    "\n",
    "# tuple(_do_filter(_parse_text_el(text)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def _do_sentence(_out):\n",
    "    sentence = []\n",
    "    result = []\n",
    "\n",
    "    for text, lemma in _out:\n",
    "        if text is None:\n",
    "            yield \" \".join(sentence), tuple(result)\n",
    "            sentence.clear()\n",
    "            result.clear()\n",
    "            continue\n",
    "\n",
    "        sentence.append(text)\n",
    "        result.append(lemma)\n",
    "\n",
    "    if sentence:\n",
    "        yield \" \".join(sentence), result\n",
    "\n",
    "# tuple(_do_sentence(_do_filter(_parse_text_el(text))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def _gen_sentence(text):\n",
    "    yield from _do_sentence(_do_filter(_parse_text_el(text)))\n",
    "\n",
    "# tuple(_gen_sentence(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def gen_sentences(*texts, count=10):\n",
    "    sentences = {}\n",
    "    for text in texts:\n",
    "        for sentence, lemmas in _gen_sentence(text):\n",
    "            if exist := sentences.get(sentence):\n",
    "                continue\n",
    "                assert exist == lemmas, (exist, lemmas)\n",
    "            sentences[sentence] = lemmas\n",
    "\n",
    "            if count is not None and len(sentences) >= count:\n",
    "                break\n",
    "\n",
    "        if count is not None and len(sentences) >= count:\n",
    "                break\n",
    "\n",
    "    return sentences\n",
    "\n",
    "sentences = gen_sentences(*root.getchildren()[1:], count=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "106892"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class AbstractLemmatizer:\n",
    "    def __call__(self, sentence: str) -> tuple:\n",
    "        raise NotImplementedError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Dummy(AbstractLemmatizer):\n",
    "    def _parse(self, word):\n",
    "        return word\n",
    "\n",
    "    def __call__(self, sentence: str):\n",
    "        return tuple(\n",
    "            self._parse(word)\n",
    "            for word in sentence.split()\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class MyStem3(AbstractLemmatizer):\n",
    "    def __init__(self):\n",
    "        import pymystem3\n",
    "        self.m = m = pymystem3.Mystem()\n",
    "\n",
    "    @staticmethod\n",
    "    def check_word(analyze_result):\n",
    "        orig_word: str = analyze_result['text'].strip()\n",
    "\n",
    "        try:\n",
    "            word: str = analyze_result['analysis'][0]['lex'].strip()\n",
    "        except (KeyError, IndexError):\n",
    "            word: str = orig_word\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        return tuple(x for word in self.m.analyze(sentence)\n",
    "            if (x := self.check_word(word))\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Morphy2(Dummy):\n",
    "    def __init__(self):\n",
    "        import pymorphy2\n",
    "        self.m = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    def _parse(self, word):\n",
    "        return self.m.parse(word)[0].normal_form"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class NLTKL(Dummy):\n",
    "    def __init__(self):\n",
    "        from nltk.stem.snowball import RussianStemmer\n",
    "        self.m = RussianStemmer()\n",
    "\n",
    "    def _parse(self, word):\n",
    "        return self.m.stem(word)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class SpaCY(Dummy):\n",
    "    def __init__(self):\n",
    "        from spacy.lemmatizer import Lemmatizer\n",
    "        from spacy.lookups import Lookups\n",
    "        lookups = Lookups()\n",
    "        lookups.add_table(\"lemma_rules\", {\"noun\": [[\"s\", \"\"]]})\n",
    "        self.l = Lemmatizer(lookups)\n",
    "    def _parse(self, word):\n",
    "        return self.l(word, \"NOUN\")[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "lemmatizers = [\n",
    "    Dummy(),\n",
    "    MyStem3(),\n",
    "    Morphy2(),\n",
    "    NLTKL(),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "('школ', 'злослов', 'уч', 'прикус', 'язык')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _test(text: str, lemmas_: tuple, l: AbstractLemmatizer) -> Tuple[int, int]:\n",
    "    result = set(lemmas_)\n",
    "    return len(set(l(text)).intersection(result)), len(result)\n",
    "\n",
    "\n",
    "print(_test(*tuple(sentences.items())[0], lemmatizers[-1]))\n",
    "\n",
    "lemmatizers[-1](tuple(sentences.items())[0][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def do_test(sentences: dict, l: AbstractLemmatizer):\n",
    "    good = 0\n",
    "    all_ = 0\n",
    "    start = time()\n",
    "    for text, lemmas in sentences.items():\n",
    "        _g, _a = _test(text, lemmas, l)\n",
    "        good += _g\n",
    "        all_ += _a\n",
    "\n",
    "    finish = time() - start\n",
    "\n",
    "    return good, all_, finish"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy : 48.550% : 1860743.2113 words/s\n",
      "MyStem3 : 80.071% : 18537.3361 words/s\n",
      "Morphy2 : 79.994% : 4078.2828 words/s\n",
      "NLTKL : 34.932% : 18279.6556 words/s\n"
     ]
    }
   ],
   "source": [
    "for l in lemmatizers:\n",
    "    g, a, tm = tuple(do_test(sentences, l))\n",
    "    print(f\"{l.__class__.__name__} : {100 * g / a:.3f}% : {a / tm:.4f} words/s\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}