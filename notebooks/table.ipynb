{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(\"../data/annot.opcorpora.xml\", \"rt\") as f:\n",
    "    root = etree.fromstring(f.read().encode())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def _parse_text_el(text_el):\n",
    "    for paragraph in text_el.find('paragraphs').getchildren():\n",
    "        for sentence in paragraph.getchildren():\n",
    "            # TODO: Clean\n",
    "            for token in sentence.find('tokens').getchildren():\n",
    "                text = token.get('text')\n",
    "                lemma = token.find(\".//l\").get('t')\n",
    "                yield text, lemma\n",
    "            yield None, None\n",
    "\n",
    "# tuple(_parse_text_el(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "good_chars = \"абвгдежзийклмнопрстуфхцчшщъыьэюя\"\n",
    "good_chars += good_chars.upper()\n",
    "\n",
    "def _cleanup(raw_text):\n",
    "    return \"\".join(ch.lower() if ch in good_chars else ' '\n",
    "                   for ch in raw_text)\n",
    "\n",
    "def _do_filter(_out):\n",
    "    for text, lemma in _out:\n",
    "        if text is None:\n",
    "            yield text, lemma\n",
    "            continue\n",
    "\n",
    "        if text := _cleanup(text).strip():\n",
    "            yield text, _cleanup(lemma).strip()\n",
    "\n",
    "# tuple(_do_filter(_parse_text_el(text)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def _do_sentence(_out):\n",
    "    sentence = []\n",
    "    result = []\n",
    "\n",
    "    for text, lemma in _out:\n",
    "        if text is None:\n",
    "            yield \" \".join(sentence), tuple(result)\n",
    "            sentence.clear()\n",
    "            result.clear()\n",
    "            continue\n",
    "\n",
    "        sentence.append(text)\n",
    "        result.append(lemma)\n",
    "\n",
    "    if sentence:\n",
    "        yield \" \".join(sentence), result\n",
    "\n",
    "# tuple(_do_sentence(_do_filter(_parse_text_el(text))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def _gen_sentence(text):\n",
    "    yield from _do_sentence(_do_filter(_parse_text_el(text)))\n",
    "\n",
    "# tuple(_gen_sentence(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def gen_sentences(*texts, count=10):\n",
    "    sentences = {}\n",
    "    for text in texts:\n",
    "        for sentence, lemmas in _gen_sentence(text):\n",
    "            if exist := sentences.get(sentence):\n",
    "                continue\n",
    "                assert exist == lemmas, (exist, lemmas)\n",
    "            sentences[sentence] = lemmas\n",
    "\n",
    "            if len(sentences) >= count:\n",
    "                break\n",
    "\n",
    "        if len(sentences) >= count:\n",
    "                break\n",
    "\n",
    "    return sentences\n",
    "\n",
    "sentences = gen_sentences(*root.getchildren()[1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class AbstractLemmatizer:\n",
    "    def __call__(self, sentence: str) -> tuple:\n",
    "        raise NotImplementedError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Dummy(AbstractLemmatizer):\n",
    "    def __call__(self, sentence):\n",
    "        return tuple(sentence.split())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class MyStem3(AbstractLemmatizer):\n",
    "    def __init__(self):\n",
    "        import pymystem3\n",
    "        self.m = m = pymystem3.Mystem()\n",
    "\n",
    "    @staticmethod\n",
    "    def check_word(analyze_result):\n",
    "        orig_word: str = analyze_result['text'].strip()\n",
    "\n",
    "        try:\n",
    "            word: str = analyze_result['analysis'][0]['lex'].strip()\n",
    "        except (KeyError, IndexError):\n",
    "            word: str = orig_word\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        return tuple(x for word in self.m.analyze(sentence)\n",
    "            if (x := self.check_word(word))\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class Morphy2(Dummy):\n",
    "    def __init__(self):\n",
    "        import pymorphy2\n",
    "        self.m = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    def _parse(self, word):\n",
    "        return self.m.parse(word)[0].normal_form\n",
    "\n",
    "    def __call__(self, sentence: str):\n",
    "        return tuple(\n",
    "            self._parse(word)\n",
    "            for word in super(Morphy2, self).__call__(sentence)\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "lemmatizers = [\n",
    "    Dummy(),\n",
    "    MyStem3(),\n",
    "    Morphy2()\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _test(text: str, lemmas_: tuple, l: AbstractLemmatizer) -> float:\n",
    "    result = set(lemmas_)\n",
    "    return len(set(l(text)).intersection(result)) / len(result)\n",
    "\n",
    "\n",
    "_test(*tuple(sentences.items())[0], MyStem3())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def do_test(sentences: dict, l: AbstractLemmatizer):\n",
    "    for text, lemmas in sentences.items():\n",
    "        yield _test(text, lemmas, l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Dummy object at 0x11593f040> 5.351091851696689\n",
      "<__main__.MyStem3 object at 0x11593f190> 8.302871165572778\n",
      "<__main__.Morphy2 object at 0x1159589d0> 8.471871654331332\n"
     ]
    }
   ],
   "source": [
    "for l in lemmatizers:\n",
    "    print(l, sum(do_test(sentences, l)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}